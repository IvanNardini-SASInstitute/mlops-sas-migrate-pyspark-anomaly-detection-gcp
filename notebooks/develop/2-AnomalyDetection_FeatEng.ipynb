{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Anomaly detection in cellular networks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Introduction\n",
    "\n",
    "The purpose of this notebook is to solve a anomaly detection problem proposed as a competition in the Kaggle InClass platform.\n",
    "\n",
    "## 2. Problem description\n",
    "\n",
    "### Context:\n",
    "\n",
    "Traditionally, the design of a cellular network focuses on the optimization of energy and resources that guarantees a smooth operation even during peak hours (i.e. periods with higher traffic load). \n",
    "However, this implies that cells are most of the time overprovisioned of radio resources. \n",
    "Next generation cellular networks ask for a dynamic management and configuration in order to adapt to the varying user demands in the most efficient way with regards to energy savings and utilization of frequency resources. \n",
    "If the network operator were capable of anticipating to those variations in the users’ traffic demands, a more efficient management of the scarce (and expensive) network resources would be possible.\n",
    "Current research in mobile networks looks upon Machine Learning (ML) techniques to help manage those resources. \n",
    "In this case, you will explore the possibilities of ML to detect abnormal behaviors in the utilization of the network that would motivate a change in the configuration of the base station.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Objective\n",
    "\n",
    "The objective of the network optimization team is to analyze traces of past activity, which will be used to train an ML system capable of classifying samples of current activity as:\n",
    " - 0 (normal): current activity corresponds to normal behavior of any working day and. Therefore, no re-configuration or redistribution of resources is needed.\n",
    " - 1 (unusual): current activity slightly differs from the behavior usually observed for that time of the day (e.g. due to a strike, demonstration, sports event, etc.), which should trigger a reconfiguration of the base station."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset\n",
    "\n",
    "The dataset has been obtained from a real LTE deployment. During two weeks, different metrics were gathered from a set of 10 base stations, each having a different number of cells, every 15 minutes. \n",
    "\n",
    "The dataset is provided in the form of a csv file, where each row corresponds to a sample obtained from one particular cell at a certain time. Each data example contains the following features:\n",
    "\n",
    " - Time : hour of the day (in the format hh:mm) when the sample was generated.\n",
    " - CellName1: text string used to uniquely identify the cell that generated the current sample. CellName is in the form xαLTE, where x identifies the base station, and α the cell within that base station (see the example in the right figure).\n",
    " - PRBUsageUL and PRBUsageDL: level of resource utilization in that cell measured as the portion of Physical Radio Blocks (PRB) that were in use (%) in the previous 15 minutes. Uplink (UL) and downlink (DL) are measured separately.\n",
    " - meanThrDL and meanThrUL: average carried traffic (in Mbps) during the past 15 minutes. Uplink (UL) and downlink (DL) are measured separately.\n",
    " - maxThrDL and maxThrUL: maximum carried traffic (in Mbps) measured in the last 15 minutes. Uplink (UL) and downlink (DL) are measured separately.\n",
    " - meanUEDL and meanUEUL: average number of user equipment (UE) devices that were simultaneously active during the last 15 minutes. Uplink (UL) and downlink (DL) are measured separately.\n",
    " - maxUEDL and maxUEUL: maximum number of user equipment (UE) devices that were simultaneously active during the last 15 minutes. Uplink (UL) and downlink (DL) are measured separately.\n",
    " - maxUE_UL+DL: maximum number of user equipment (UE) devices that were active simultaneously in the last 15 minutes, regardless of UL and DL.\n",
    " - Unusual: labels for supervised learning. A value of 0 determines that the sample corresponds to normal operation, a value of 1 identifies unusual behavior."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import random\n",
    "random.seed(888) #set seed for reproducibility\n",
    "from zipfile import ZipFile\n",
    "from IPython.display import Image\n",
    "\n",
    "\n",
    "#Analysis\n",
    "import pyspark\n",
    "try:\n",
    "    from pyspark import SparkContext, SparkConf\n",
    "    from pyspark.sql import SparkSession\n",
    "except ImportError as e:\n",
    "    print('WARN: Something wrong with pyspark library. Please check configuration settings!')\n",
    "    \n",
    "#Feature Engineering\n",
    "from pyspark.sql.functions import col, when, lit, array, explode, rand\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.feature import VectorAssembler, StandardScaler\n",
    "    \n",
    "# Reloads functions each time so you can edit a script and not need to restart the kernel\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helpers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-22T23:24:55.390680Z",
     "start_time": "2019-02-22T23:24:55.344380Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_root_dir(src:str, max_nest:int) -> str:\n",
    "    '''\n",
    "    Specify paths and appending directories with relevant python source code.\n",
    "    '''\n",
    "    root_dir = os.curdir\n",
    "    nest = 0\n",
    "    while src not in os.listdir(root_dir) and nest < max_nest:\n",
    "        root_dir = os.path.join(os.pardir, root_dir)     # Look up the directory structure for a src directory\n",
    "        nest += 1\n",
    "        \n",
    "    # If you don't find the src directory, the root directory is this directory\n",
    "    root_dir = os.path.abspath(root_dir) if nest < max_nest else os.path.abspath(\n",
    "    os.curdir)\n",
    "    \n",
    "    return root_dir\n",
    "\n",
    "def set_src(root_dir:str, src:str) -> str:\n",
    "    '''\n",
    "     Get the source directory and append path to access python packages/scripts within directory\n",
    "    '''\n",
    "    if src in os.listdir(root_dir):\n",
    "        src_dir = os.path.join(root_dir, src)\n",
    "        sys.path.append(src_dir)\n",
    "    return sys.path[-1]\n",
    "\n",
    "def set_folder(root_dir:str, folder:str) -> str:\n",
    "    '''\n",
    "    Set the folder path based on the folder name\n",
    "    '''\n",
    "    folder_path = os.path.join(\n",
    "        root_dir, folder) if folder in os.listdir(root_dir) else os.curdir\n",
    "    return folder_path\n",
    "\n",
    "def set_path(path:str, dirname:str) -> str:\n",
    "    '''\n",
    "    '''\n",
    "    return os.path.join(path, dirname)\n",
    "\n",
    "def unzip(inpath:str, outpath:str) -> None:\n",
    "    zf = ZipFile(inpath, 'r')\n",
    "    zf.extractall(outpath)\n",
    "    zf.close()\n",
    "\n",
    "def set_weights(labels):\n",
    "    return when(labels == 0, zratio).otherwise(1*(1-zratio))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "root_dir = get_root_dir('src', 5)\n",
    "src_dir = set_src(root_dir, 'src')\n",
    "data_dir = set_folder(root_dir, 'data')\n",
    "raw_data_dir = set_path(data_dir, 'raw')\n",
    "interim_data_dir = set_path(data_dir, 'interim')\n",
    "processed_data_dir = set_path(data_dir, 'processed')\n",
    "figures_dir = set_folder(root_dir, 'figures')\n",
    "features_dir = set_folder(root_dir, 'features')\n",
    "models_dir = set_folder(root_dir, 'models')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initiate Spark session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#If not exists create a spark session named Anomaly Detection where the master node is local\n",
    "spark = SparkSession.builder \\\n",
    "    .master(\"local[4]\") \\\n",
    "    .appName(\"Anomaly Detection\") \\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://itacivnard2.emea.SAS.com:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.0.0-preview</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[4]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>Anomaly Detection</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x1ae755fa048>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.getActiveSession()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_path = set_path(processed_data_dir, 'ML-MATT-CompetitionQT1920_train_processed.csv')\n",
    "test_path = set_path(processed_data_dir, 'ML-MATT-CompetitionQT1920_test_processed.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = spark.read.option(\"header\", True) \\\n",
    "                .option(\"delimiter\", ',') \\\n",
    "                .option(\"inferSchema\" , \"true\") \\\n",
    "                .csv(train_path)\n",
    "\n",
    "test_df = spark.read.option(\"header\", True) \\\n",
    "                .option(\"delimiter\", ',') \\\n",
    "                .option(\"inferSchema\" , \"true\") \\\n",
    "                .csv(test_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- CellName: string (nullable = true)\n",
      " |-- PRBUsageUL: double (nullable = true)\n",
      " |-- PRBUsageDL: double (nullable = true)\n",
      " |-- meanThr_DL: double (nullable = true)\n",
      " |-- meanThr_UL: double (nullable = true)\n",
      " |-- maxThr_DL: double (nullable = true)\n",
      " |-- maxThr_UL: double (nullable = true)\n",
      " |-- meanUE_DL: double (nullable = true)\n",
      " |-- meanUE_UL: double (nullable = true)\n",
      " |-- maxUE_DL: double (nullable = true)\n",
      " |-- maxUE_UL: double (nullable = true)\n",
      " |-- Unusual: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+----------+----------+----------+----------+---------+---------+---------+---------+--------+--------+-------+\n",
      "|CellName|PRBUsageUL|PRBUsageDL|meanThr_DL|meanThr_UL|maxThr_DL|maxThr_UL|meanUE_DL|meanUE_UL|maxUE_DL|maxUE_UL|Unusual|\n",
      "+--------+----------+----------+----------+----------+---------+---------+---------+---------+--------+--------+-------+\n",
      "|   3BLTE|    11.642|     1.393|      0.37|     0.041|   15.655|    0.644|    1.114|    1.025|     4.0|     3.0|      1|\n",
      "|   1BLTE|    21.791|     1.891|     0.537|     0.268|   10.273|    1.154|    1.353|    1.085|     6.0|     4.0|      1|\n",
      "|   9BLTE|     0.498|     0.398|     0.015|      0.01|    0.262|    0.164|    0.995|    0.995|     1.0|     1.0|      1|\n",
      "|   4ALTE|     1.891|     1.095|      0.94|     0.024|   60.715|    0.825|    1.035|    0.995|     2.0|     2.0|      1|\n",
      "|  10BLTE|     0.303|     0.404|     0.016|     0.013|    0.348|    0.168|    1.011|    1.011|     2.0|     1.0|      0|\n",
      "+--------+----------+----------+----------+----------+---------+---------+---------+---------+--------+--------+-------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_df.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Feature Engineering\n",
    "\n",
    "Because we have:\n",
    "\n",
    " - unbalanced sample\n",
    " - different scales \n",
    " \n",
    "we need to implement some transformations:\n",
    "\n",
    " - balance the train sample with weights\n",
    " - standardize the data\n",
    " \n",
    "To do that let's create a Pipeline!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Balancing Target\n",
    "\n",
    "There are different methods to balance data:\n",
    "  1. Undersampling (the majority class)\n",
    "  2. Oversampling (the minority class) \n",
    "  3. Class weighting (assign the inverse ratio of each class as weights)\n",
    "\n",
    "Although the sample is large (Undersampling is possible), I prefer Oversampling!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ratio: 2\n"
     ]
    }
   ],
   "source": [
    "df_major_label = train_df.filter(col(\"Unusual\") == 0)\n",
    "df_minor_label= train_df.filter(col(\"Unusual\") == 1)\n",
    "ratio = int(df_major_label.count()/df_minor_label.count())\n",
    "print(\"ratio: {}\".format(ratio))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "range_ratio = range(ratio)\n",
    "oversample_df = df_minor_label.withColumn(\"Dummy\", explode(array([lit(i) for i in range_ratio]))).drop('Dummy') #Explode creates new row for each element in the array "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+----------+----------+----------+----------+---------+---------+---------+---------+--------+--------+-------+\n",
      "|CellName|PRBUsageUL|PRBUsageDL|meanThr_DL|meanThr_UL|maxThr_DL|maxThr_UL|meanUE_DL|meanUE_UL|maxUE_DL|maxUE_UL|Unusual|\n",
      "+--------+----------+----------+----------+----------+---------+---------+---------+---------+--------+--------+-------+\n",
      "|   3BLTE|    11.642|     1.393|      0.37|     0.041|   15.655|    0.644|    1.114|    1.025|     4.0|     3.0|      1|\n",
      "|   3BLTE|    11.642|     1.393|      0.37|     0.041|   15.655|    0.644|    1.114|    1.025|     4.0|     3.0|      1|\n",
      "|   1BLTE|    21.791|     1.891|     0.537|     0.268|   10.273|    1.154|    1.353|    1.085|     6.0|     4.0|      1|\n",
      "|   1BLTE|    21.791|     1.891|     0.537|     0.268|   10.273|    1.154|    1.353|    1.085|     6.0|     4.0|      1|\n",
      "|   9BLTE|     0.498|     0.398|     0.015|      0.01|    0.262|    0.164|    0.995|    0.995|     1.0|     1.0|      1|\n",
      "|   9BLTE|     0.498|     0.398|     0.015|      0.01|    0.262|    0.164|    0.995|    0.995|     1.0|     1.0|      1|\n",
      "|   4ALTE|     1.891|     1.095|      0.94|     0.024|   60.715|    0.825|    1.035|    0.995|     2.0|     2.0|      1|\n",
      "|   4ALTE|     1.891|     1.095|      0.94|     0.024|   60.715|    0.825|    1.035|    0.995|     2.0|     2.0|      1|\n",
      "|   4BLTE|      7.96|     1.393|     0.299|     0.025|   24.697|    0.451|    1.075|    1.015|     3.0|     3.0|      1|\n",
      "|   4BLTE|      7.96|     1.393|     0.299|     0.025|   24.697|    0.451|    1.075|    1.015|     3.0|     3.0|      1|\n",
      "+--------+----------+----------+----------+----------+---------+---------+---------+---------+--------+--------+-------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "oversample_df.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df_balanced = df_major_label.unionAll(oversample_df).orderBy(rand())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The ratio now is 1\n"
     ]
    }
   ],
   "source": [
    "ratio_balanced = train_df_balanced.where('Unusual == 0').count()/train_df_balanced.where('Unusual == 1').count()\n",
    "print(f'The ratio now is {int(ratio_balanced)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Standardize data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+----------+----------+----------+----------+---------+---------+---------+---------+--------+--------+-------+--------------------+\n",
      "|CellName|PRBUsageUL|PRBUsageDL|meanThr_DL|meanThr_UL|maxThr_DL|maxThr_UL|meanUE_DL|meanUE_UL|maxUE_DL|maxUE_UL|Unusual|            features|\n",
      "+--------+----------+----------+----------+----------+---------+---------+---------+---------+--------+--------+-------+--------------------+\n",
      "|   7VLTE|     0.606|     1.516|     0.149|     0.014|   16.116|    1.119|    1.071|     0.01|     3.0|     2.0|      0|[0.606,1.516,0.14...|\n",
      "|   6ULTE|     3.483|    14.328|     1.792|     0.081|   14.384|    2.295|    1.264|     0.01|     4.0|     4.0|      1|[3.483,14.328,1.7...|\n",
      "|  10CLTE|     3.638|     0.606|      0.11|     0.019|   14.086|    0.567|    1.071|    1.021|     4.0|     2.0|      0|[3.638,0.606,0.11...|\n",
      "|   6ALTE|     6.972|     1.415|     0.434|     0.049|   19.952|    0.749|    1.091|     0.01|     4.0|     3.0|      0|[6.972,1.415,0.43...|\n",
      "|   6VLTE|     2.425|     3.436|     0.342|     0.077|   15.633|    6.733|    1.374|     0.01|     6.0|     4.0|      0|[2.425,3.436,0.34...|\n",
      "+--------+----------+----------+----------+----------+---------+---------+---------+---------+--------+--------+-------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "continuous_input_vars = ['PRBUsageUL', 'PRBUsageDL', 'meanThr_DL', \n",
    "                         'meanThr_UL', 'maxThr_DL', 'maxThr_UL', \n",
    "                         'meanUE_DL', 'meanUE_UL', 'maxUE_DL', 'maxUE_UL']\n",
    "\n",
    "assembler = VectorAssembler(inputCols=continuous_input_vars,\n",
    "                                   outputCol=\"features\")\n",
    "\n",
    "train_df_feat = assembler.transform(train_df_balanced)\n",
    "train_df_feat.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+--------------------+-------+\n",
      "|CellName|        features_std|Unusual|\n",
      "+--------+--------------------+-------+\n",
      "|   7VLTE|[-0.8474628563740...|      0|\n",
      "|   6ULTE|[-0.4931119676639...|      1|\n",
      "|  10CLTE|[-0.4740211133886...|      0|\n",
      "|   6ALTE|[-0.0633829962667...|      0|\n",
      "|   6VLTE|[-0.6234224439431...|      0|\n",
      "+--------+--------------------+-------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "scaler = StandardScaler(withMean=True, withStd=True, inputCol=assembler.getOutputCol(), outputCol=\"features_std\")\n",
    "scaler_fit = scaler.fit(train_df_feat)\n",
    "train_df_scaled = scaler_fit.transform(train_df_feat)\n",
    "train_df_scaled = train_df_scaled.select(\"CellName\", \"features_std\", \"Unusual\")\n",
    "train_df_scaled.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+----------+----------+----------+----------+---------+---------+---------+---------+--------+--------+--------------------+\n",
      "|CellName|PRBUsageUL|PRBUsageDL|meanThr_DL|meanThr_UL|maxThr_DL|maxThr_UL|meanUE_DL|meanUE_UL|maxUE_DL|maxUE_UL|            features|\n",
      "+--------+----------+----------+----------+----------+---------+---------+---------+---------+--------+--------+--------------------+\n",
      "|   6ALTE|     3.781|     1.493|     0.575|     0.042|   22.659|    0.743|    0.985|     0.01|     3.0|     2.0|[3.781,1.493,0.57...|\n",
      "|   6ULTE|     2.021|     3.335|     0.569|     0.075|   29.265|    1.049|    1.314|     0.01|     6.0|     3.0|[2.021,3.335,0.56...|\n",
      "|   2ALTE|     0.505|     0.404|     0.014|      0.01|    0.227|    0.097|    1.011|     0.01|     2.0|     1.0|[0.505,0.404,0.01...|\n",
      "|   3CLTE|     1.011|     0.505|     0.238|     0.021|   20.962|    0.609|    1.011|    1.011|     2.0|     1.0|[1.011,0.505,0.23...|\n",
      "|   6CLTE|     3.881|     0.498|     0.076|     0.041|    3.936|    1.768|    1.025|     0.01|     3.0|     2.0|[3.881,0.498,0.07...|\n",
      "+--------+----------+----------+----------+----------+---------+---------+---------+---------+--------+--------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_df_feat = assembler.transform(test_df)\n",
    "test_df_feat.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+--------------------+\n",
      "|CellName|        features_std|\n",
      "+--------+--------------------+\n",
      "|   6ALTE|[-0.4564082607346...|\n",
      "|   6ULTE|[-0.6731818318607...|\n",
      "|   2ALTE|[-0.8599027033534...|\n",
      "|   3CLTE|[-0.7975803016546...|\n",
      "|   6CLTE|[-0.4440915805569...|\n",
      "+--------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_df_scaled = scaler_fit.transform(test_df_feat)\n",
    "test_df_scaled = test_df_scaled.select(\"CellName\", \"features_std\")\n",
    "test_df_scaled.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Store Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "# suppose to work\n",
    "# scaler_fit.write().overwrite().save(features_dir)\n",
    "train_features_path = set_path(interim_data_dir, 'ML-MATT-CompetitionQT1920_train_features.csv')\n",
    "test_features_path = set_path(interim_data_dir, 'ML-MATT-CompetitionQT1920_test_features.csv')\n",
    "train_df_scaled.toPandas().to_csv(train_features_path, index=False)\n",
    "test_df.toPandas().to_csv(test_features_path, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we get features. We are ready to train the model."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.11"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
